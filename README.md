# Feature Selection com Permutation Importance üîÄ

Este reposit√≥rio demonstra como aplicar **sele√ß√£o de vari√°veis** utilizando o m√©todo de **import√¢ncia por permuta√ß√£o** com `scikit-learn`.

## üí° Sobre o projeto

A ideia principal √© utilizar um m√©todo **simples, intuitivo e modelo-agn√≥stico** para identificar as vari√°veis com maior poder preditivo. Diferente de m√©todos baseados em coeficientes (como regress√£o linear) ou import√¢ncia de √°rvores (como random forests), a **import√¢ncia por permuta√ß√£o** avalia diretamente a varia√ß√£o na performance do modelo ao embaralhar cada feature individualmente.

Este m√©todo √©:
- Independente do tipo de modelo utilizado;
- Baseado apenas na **m√©trica de desempenho**;
- √ötil para avaliar a contribui√ß√£o real de cada vari√°vel.

## üß™ Como funciona

1. Um modelo √© treinado com as features originais.
2. Cada feature √© embaralhada individualmente.
3. O impacto dessa altera√ß√£o na **acur√°cia (ou outra m√©trica)** √© medido.
4. Quanto maior a queda no desempenho, mais importante √© a feature.

‚ö†Ô∏è Aten√ß√£o:
- Pode apresentar vi√©s com **features altamente correlacionadas**.
- Precisa de um **modelo supervisionado** (com r√≥tulo).
- Modelos sobreajustados podem distorcer a avalia√ß√£o.

## üõ†Ô∏è Instru√ß√µes de uso

### 1. Clonar o reposit√≥rio

```bash
git clone https://github.com/raulward/feature_selection_permutation_importance.git
cd feature_selection_permutation_importance
